{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\guoca\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\guoca\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\guoca\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\guoca\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC, RandomForestRegressor as RFR, GradientBoostingClassifier as XGBoost\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = pd.read_csv(\"Data/clean_ratings.csv\", infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "profID                   int64\n",
       "attendanceMandatory       bool\n",
       "class                   object\n",
       "comment                 object\n",
       "date                    object\n",
       "difficultyRating       float64\n",
       "grade                   object\n",
       "helpfulRating          float64\n",
       "isForCredit               bool\n",
       "isForOnlineClass          bool\n",
       "ratingTags              object\n",
       "wouldTakeAgain            bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profID</th>\n",
       "      <th>attendanceMandatory</th>\n",
       "      <th>class</th>\n",
       "      <th>comment</th>\n",
       "      <th>date</th>\n",
       "      <th>difficultyRating</th>\n",
       "      <th>grade</th>\n",
       "      <th>helpfulRating</th>\n",
       "      <th>isForCredit</th>\n",
       "      <th>isForOnlineClass</th>\n",
       "      <th>ratingTags</th>\n",
       "      <th>wouldTakeAgain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7964</td>\n",
       "      <td>False</td>\n",
       "      <td>ANTHRCUL101</td>\n",
       "      <td>Fricke is the man. Entire class probably took ...</td>\n",
       "      <td>2019-04-28 17:13:12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>['Respected', 'Inspirational', 'Amazing Lectur...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7964</td>\n",
       "      <td>False</td>\n",
       "      <td>ANTHRO101</td>\n",
       "      <td>Tom Fricke is one of those professors you will...</td>\n",
       "      <td>2019-01-08 18:41:24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A+</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>['Accessible Outside Class', 'Hilarious', 'Ama...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7964</td>\n",
       "      <td>False</td>\n",
       "      <td>ANTHRCUL101</td>\n",
       "      <td>Prof. Fricke is amazing. He is hilarious and t...</td>\n",
       "      <td>2018-12-16 03:11:18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>['Hilarious', 'Graded By Few Things', 'Caring']</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7964</td>\n",
       "      <td>False</td>\n",
       "      <td>CULTANTHRO101</td>\n",
       "      <td>Such an easy class. Exams were exactly like th...</td>\n",
       "      <td>2018-12-12 10:03:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>['Accessible Outside Class', 'Graded By Few Th...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7964</td>\n",
       "      <td>False</td>\n",
       "      <td>ANTHRCUL101</td>\n",
       "      <td>Easiest class i have taken at UM. The exams to...</td>\n",
       "      <td>2018-12-11 16:33:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A+</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>['Respected', 'Hilarious', 'Amazing Lectures']</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   profID  attendanceMandatory          class  \\\n",
       "0    7964                False    ANTHRCUL101   \n",
       "1    7964                False      ANTHRO101   \n",
       "2    7964                False    ANTHRCUL101   \n",
       "3    7964                False  CULTANTHRO101   \n",
       "4    7964                False    ANTHRCUL101   \n",
       "\n",
       "                                             comment                 date  \\\n",
       "0  Fricke is the man. Entire class probably took ...  2019-04-28 17:13:12   \n",
       "1  Tom Fricke is one of those professors you will...  2019-01-08 18:41:24   \n",
       "2  Prof. Fricke is amazing. He is hilarious and t...  2018-12-16 03:11:18   \n",
       "3  Such an easy class. Exams were exactly like th...  2018-12-12 10:03:19   \n",
       "4  Easiest class i have taken at UM. The exams to...  2018-12-11 16:33:00   \n",
       "\n",
       "   difficultyRating grade  helpfulRating  isForCredit  isForOnlineClass  \\\n",
       "0               1.0     A            5.0        False             False   \n",
       "1               1.0    A+            5.0        False             False   \n",
       "2               1.0     A            5.0        False             False   \n",
       "3               1.0     A            5.0        False             False   \n",
       "4               1.0    A+            5.0        False             False   \n",
       "\n",
       "                                          ratingTags  wouldTakeAgain  \n",
       "0  ['Respected', 'Inspirational', 'Amazing Lectur...            True  \n",
       "1  ['Accessible Outside Class', 'Hilarious', 'Ama...            True  \n",
       "2    ['Hilarious', 'Graded By Few Things', 'Caring']            True  \n",
       "3  ['Accessible Outside Class', 'Graded By Few Th...            True  \n",
       "4     ['Respected', 'Hilarious', 'Amazing Lectures']            True  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profID</th>\n",
       "      <th>difficultyRating</th>\n",
       "      <th>helpfulRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.165000e+04</td>\n",
       "      <td>51630.000000</td>\n",
       "      <td>51630.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.038128e+06</td>\n",
       "      <td>2.999806</td>\n",
       "      <td>3.801511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.262400e+05</td>\n",
       "      <td>1.179900</td>\n",
       "      <td>1.445799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.775000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.294040e+05</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.951030e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.656242e+06</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.880778e+06</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             profID  difficultyRating  helpfulRating\n",
       "count  5.165000e+04      51630.000000   51630.000000\n",
       "mean   1.038128e+06          2.999806       3.801511\n",
       "std    7.262400e+05          1.179900       1.445799\n",
       "min    7.775000e+03          1.000000       1.000000\n",
       "25%    4.294040e+05          2.000000       3.000000\n",
       "50%    8.951030e+05          3.000000       4.000000\n",
       "75%    1.656242e+06          4.000000       5.000000\n",
       "max    2.880778e+06          5.000000       5.000000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profs = pd.read_csv(\"Data/clean_prof_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profID</th>\n",
       "      <th>avgDifficulty</th>\n",
       "      <th>avgRating</th>\n",
       "      <th>department</th>\n",
       "      <th>firstName</th>\n",
       "      <th>lastName</th>\n",
       "      <th>numRatings</th>\n",
       "      <th>wouldTakeAgainPercent</th>\n",
       "      <th>fullName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7775</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Mechanical Engineering</td>\n",
       "      <td>Alan</td>\n",
       "      <td>Wineman</td>\n",
       "      <td>34</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Alan Wineman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7964</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Anthropology</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>Fricke</td>\n",
       "      <td>114</td>\n",
       "      <td>95.0</td>\n",
       "      <td>Thomas Fricke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8045</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Biology</td>\n",
       "      <td>Julian</td>\n",
       "      <td>Adams</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Julian Adams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8189</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Music</td>\n",
       "      <td>Deborah</td>\n",
       "      <td>Chodacki</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deborah Chodacki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10260</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Political Science</td>\n",
       "      <td>Arlene</td>\n",
       "      <td>Saxonhouse</td>\n",
       "      <td>86</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Arlene Saxonhouse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   profID  avgDifficulty  avgRating              department firstName  \\\n",
       "0    7775            2.3        4.4  Mechanical Engineering      Alan   \n",
       "1    7964            1.6        4.5            Anthropology    Thomas   \n",
       "2    8045            2.6        3.2                 Biology    Julian   \n",
       "3    8189            3.1        4.6                   Music   Deborah   \n",
       "4   10260            4.0        2.3       Political Science    Arlene   \n",
       "\n",
       "     lastName  numRatings  wouldTakeAgainPercent           fullName  \n",
       "0     Wineman          34                   80.0       Alan Wineman  \n",
       "1      Fricke         114                   95.0      Thomas Fricke  \n",
       "2       Adams          22                    NaN       Julian Adams  \n",
       "3    Chodacki           8                    NaN   Deborah Chodacki  \n",
       "4  Saxonhouse          86                   66.0  Arlene Saxonhouse  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_profs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "profID                     int64\n",
       "avgDifficulty            float64\n",
       "avgRating                float64\n",
       "department                object\n",
       "firstName                 object\n",
       "lastName                  object\n",
       "numRatings                 int64\n",
       "wouldTakeAgainPercent    float64\n",
       "fullName                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_profs.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profs[\"firstName\"] = df_profs[\"firstName\"].apply(lambda x: x.strip())\n",
    "df_profs[\"lastName\"] = df_profs[\"lastName\"].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names = df_profs[[\"profID\", \"firstName\", \"lastName\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51650, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profID</th>\n",
       "      <th>attendanceMandatory</th>\n",
       "      <th>class</th>\n",
       "      <th>comment</th>\n",
       "      <th>date</th>\n",
       "      <th>difficultyRating</th>\n",
       "      <th>grade</th>\n",
       "      <th>helpfulRating</th>\n",
       "      <th>isForCredit</th>\n",
       "      <th>isForOnlineClass</th>\n",
       "      <th>ratingTags</th>\n",
       "      <th>wouldTakeAgain</th>\n",
       "      <th>firstName</th>\n",
       "      <th>lastName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7964</td>\n",
       "      <td>False</td>\n",
       "      <td>ANTHRCUL101</td>\n",
       "      <td>Fricke is the man. Entire class probably took ...</td>\n",
       "      <td>2019-04-28 17:13:12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>['Respected', 'Inspirational', 'Amazing Lectur...</td>\n",
       "      <td>True</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>Fricke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7964</td>\n",
       "      <td>False</td>\n",
       "      <td>ANTHRO101</td>\n",
       "      <td>Tom Fricke is one of those professors you will...</td>\n",
       "      <td>2019-01-08 18:41:24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A+</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>['Accessible Outside Class', 'Hilarious', 'Ama...</td>\n",
       "      <td>True</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>Fricke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7964</td>\n",
       "      <td>False</td>\n",
       "      <td>ANTHRCUL101</td>\n",
       "      <td>Prof. Fricke is amazing. He is hilarious and t...</td>\n",
       "      <td>2018-12-16 03:11:18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>['Hilarious', 'Graded By Few Things', 'Caring']</td>\n",
       "      <td>True</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>Fricke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7964</td>\n",
       "      <td>False</td>\n",
       "      <td>CULTANTHRO101</td>\n",
       "      <td>Such an easy class. Exams were exactly like th...</td>\n",
       "      <td>2018-12-12 10:03:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>['Accessible Outside Class', 'Graded By Few Th...</td>\n",
       "      <td>True</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>Fricke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7964</td>\n",
       "      <td>False</td>\n",
       "      <td>ANTHRCUL101</td>\n",
       "      <td>Easiest class i have taken at UM. The exams to...</td>\n",
       "      <td>2018-12-11 16:33:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A+</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>['Respected', 'Hilarious', 'Amazing Lectures']</td>\n",
       "      <td>True</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>Fricke</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   profID  attendanceMandatory          class  \\\n",
       "0    7964                False    ANTHRCUL101   \n",
       "1    7964                False      ANTHRO101   \n",
       "2    7964                False    ANTHRCUL101   \n",
       "3    7964                False  CULTANTHRO101   \n",
       "4    7964                False    ANTHRCUL101   \n",
       "\n",
       "                                             comment                 date  \\\n",
       "0  Fricke is the man. Entire class probably took ...  2019-04-28 17:13:12   \n",
       "1  Tom Fricke is one of those professors you will...  2019-01-08 18:41:24   \n",
       "2  Prof. Fricke is amazing. He is hilarious and t...  2018-12-16 03:11:18   \n",
       "3  Such an easy class. Exams were exactly like th...  2018-12-12 10:03:19   \n",
       "4  Easiest class i have taken at UM. The exams to...  2018-12-11 16:33:00   \n",
       "\n",
       "   difficultyRating grade  helpfulRating  isForCredit  isForOnlineClass  \\\n",
       "0               1.0     A            5.0        False             False   \n",
       "1               1.0    A+            5.0        False             False   \n",
       "2               1.0     A            5.0        False             False   \n",
       "3               1.0     A            5.0        False             False   \n",
       "4               1.0    A+            5.0        False             False   \n",
       "\n",
       "                                          ratingTags  wouldTakeAgain  \\\n",
       "0  ['Respected', 'Inspirational', 'Amazing Lectur...            True   \n",
       "1  ['Accessible Outside Class', 'Hilarious', 'Ama...            True   \n",
       "2    ['Hilarious', 'Graded By Few Things', 'Caring']            True   \n",
       "3  ['Accessible Outside Class', 'Graded By Few Th...            True   \n",
       "4     ['Respected', 'Hilarious', 'Amazing Lectures']            True   \n",
       "\n",
       "  firstName lastName  \n",
       "0    Thomas   Fricke  \n",
       "1    Thomas   Fricke  \n",
       "2    Thomas   Fricke  \n",
       "3    Thomas   Fricke  \n",
       "4    Thomas   Fricke  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings = df_ratings.merge(df_names, how=\"inner\", on=\"profID\")\n",
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51650, 14)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No data lost, all profIDs have match in df_profs\n",
    "df_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "stopword_list = set(stopwords.words(\"english\"))\n",
    "stopword_list.update([',', '.'])\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_comment(row):\n",
    "    \"\"\"\n",
    "    Tokenize, remove stopwords and punctuations at word ends, lemmatize, and then reassemble into one string.\n",
    "    \n",
    "    If any token matches the first or last name of the professor, it is dropped.\n",
    "    \n",
    "    All numbers are dropped.\n",
    "    \n",
    "    This is done to eliminate low-impact tokens and reduce vocabulary size.\n",
    "    \n",
    "    String type output required for easier ingestion by sklearn TfidfVectorizer.\n",
    "    \"\"\"\n",
    "    comment = row.loc[\"comment\"]\n",
    "    re.sub(r\"['!\\\"#$%&\\'()*,./:;<=>?@[\\\\]^_`{|}~'] \", ' ', comment)\n",
    "    tokens = word_tokenize(comment)\n",
    "    \n",
    "    ignore_list = stopword_list.copy()\n",
    "    ignore_list.update([row.loc[\"firstName\"], row.loc[\"lastName\"]])\n",
    "    \n",
    "    tokens = [token.lower() for token in tokens if token not in ignore_list and not token.isnumeric()]\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings[\"comment\"] = df_ratings.apply(preprocess_comment, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    man entire class probably took five hour study...\n",
       "1    tom one professor never ever forget i found co...\n",
       "2    prof. amazing he hilarious tell great interest...\n",
       "3    such easy class exam exactly like practice exa...\n",
       "4    easiest class taken um the exam took majority ...\n",
       "5    this easiest course ever want well long look s...\n",
       "6    easy a. i like talked lot fieldwork made easie...\n",
       "7    take it with fricke you literally given exam q...\n",
       "8    easy class lecture brutal easily get topic com...\n",
       "9    tom hilarious lecture much fun you tell really...\n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings[\"comment\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings[\"Hot\"] = df_ratings[\"helpfulRating\"] >= 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings[\"Hot\"] = df_ratings[\"Hot\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_ratings[\"comment\"], df_ratings[\"Hot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency and TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(strip_accents=\"ascii\")\n",
    "count_vectorizer = CountVectorizer(strip_accents=\"ascii\")\n",
    "\n",
    "# note to future self: please remember to set the min_df parameter to limit the dimensionality.\n",
    "# High-dimensional encoding drastically dlows down fitting and grid searching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "train_count = count_vectorizer.fit_transform(X_train)\n",
    "test_count = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe (Global Vectors for Word Representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guoca\\anaconda3\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n",
      "C:\\Users\\guoca\\AppData\\Local\\Temp\\ipykernel_13920\\526973530.py:7: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_path, word2vec_path)\n"
     ]
    }
   ],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "glove_path = \"Data/glove.6B.100d.txt\"\n",
    "word2vec_path = glove_path + \".word2vec\"\n",
    "\n",
    "glove2word2vec(glove_path, word2vec_path)\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecVectorizer:\n",
    "    \"\"\"Encode entire comments by taking the average of the word representations\"\"\"\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dimension = 100\n",
    "\n",
    "    def transform(self, data):\n",
    "        X = np.zeros((len(data), self.dimension))\n",
    "        n = 0\n",
    "        empty_count = 0\n",
    "        \n",
    "        for sentence in data:\n",
    "            tokens = sentence.split()\n",
    "            vecs = []\n",
    "\n",
    "            for word in tokens:\n",
    "                try:\n",
    "                  # throws KeyError if word not found\n",
    "                  vec = self.word2vec.get_vector(word)\n",
    "                  vecs.append(vec)\n",
    "                except KeyError:\n",
    "                  pass\n",
    "            \n",
    "            if len(vecs) > 0:\n",
    "                vecs = np.array(vecs)\n",
    "                X[n] = vecs.mean(axis=0)\n",
    "            else:\n",
    "                empty_count += 1\n",
    "                \n",
    "            n += 1\n",
    "            \n",
    "        print(f\"Number of samples with no words found: {empty_count}/{len(data)}\")\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_vectorizer = Word2VecVectorizer(word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples with no words found: 22/38737\n",
      "Number of samples with no words found: 2/12913\n"
     ]
    }
   ],
   "source": [
    "train_word2vec = word2vec_vectorizer.transform(X_train)\n",
    "test_word2vec = word2vec_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(clf, search_grid):\n",
    "    clf = GridSearchCV(estimator=clf, param_grid=search_grid, scoring=\"f1\", n_jobs=-1, verbose=3)\n",
    "    \n",
    "    print(\"Frequency:\")\n",
    "    clf.fit(train_count, y_train)\n",
    "    count_clf = clf.best_estimator_\n",
    "    pred_count = count_clf.predict(test_count)\n",
    "    \n",
    "    # 0 for not hot, 1 for hot\n",
    "    print(classification_report(y_test, pred_count, target_names=[\"Not Hot\", \"Hot\"]))\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    print(\"TfIdf:\")\n",
    "    clf.fit(train_tfidf, y_train)\n",
    "    tfidf_clf = clf.best_estimator_\n",
    "    pred_tfidf = tfidf_clf.predict(test_tfidf)\n",
    "    \n",
    "    print(classification_report(y_test, pred_tfidf, target_names=[\"Not Hot\", \"Hot\"]))\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    print(\"Word2Vec:\")\n",
    "    clf.fit(train_word2vec, y_train)\n",
    "    word2vec_clf = clf.best_estimator_\n",
    "    pred_word2vec = word2vec_clf.predict(test_word2vec)\n",
    "    \n",
    "    print(classification_report(y_test, pred_word2vec, target_names=[\"Not Hot\", \"Hot\"]))\n",
    "    \n",
    "    return count_clf, tfidf_clf, word2vec_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency:\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  15 | elapsed:  1.9min remaining:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  15 | elapsed:  3.1min remaining:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  5.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Not Hot       0.86      0.56      0.68      4232\n",
      "         Hot       0.82      0.95      0.88      8681\n",
      "\n",
      "    accuracy                           0.83     12913\n",
      "   macro avg       0.84      0.76      0.78     12913\n",
      "weighted avg       0.83      0.83      0.82     12913\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "TfIdf:\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  15 | elapsed:  1.9min remaining:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  15 | elapsed:  3.1min remaining:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  4.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Not Hot       0.86      0.56      0.68      4232\n",
      "         Hot       0.82      0.96      0.88      8681\n",
      "\n",
      "    accuracy                           0.83     12913\n",
      "   macro avg       0.84      0.76      0.78     12913\n",
      "weighted avg       0.83      0.83      0.81     12913\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Word2Vec:\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  15 | elapsed:   39.8s remaining:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  15 | elapsed:  1.2min remaining:   37.2s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Not Hot       0.75      0.53      0.62      4232\n",
      "         Hot       0.80      0.91      0.85      8681\n",
      "\n",
      "    accuracy                           0.79     12913\n",
      "   macro avg       0.78      0.72      0.74     12913\n",
      "weighted avg       0.78      0.79      0.78     12913\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RFC(random_state=42, n_jobs=-1)\n",
    "rf_grid = {\"n_estimators\":[50, 100, 200]}\n",
    "rf_count, rf_tfidf, rf_word2vec = benchmark(rf, rf_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency:\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  15 | elapsed:  1.8min remaining:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  15 | elapsed:  1.8min remaining:   53.0s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Not Hot       0.80      0.62      0.70      4232\n",
      "         Hot       0.83      0.93      0.88      8681\n",
      "\n",
      "    accuracy                           0.83     12913\n",
      "   macro avg       0.82      0.77      0.79     12913\n",
      "weighted avg       0.82      0.83      0.82     12913\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "TfIdf:\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  15 | elapsed:  2.6min remaining:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  15 | elapsed:  2.7min remaining:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Not Hot       0.80      0.63      0.70      4232\n",
      "         Hot       0.84      0.92      0.88      8681\n",
      "\n",
      "    accuracy                           0.83     12913\n",
      "   macro avg       0.82      0.78      0.79     12913\n",
      "weighted avg       0.82      0.83      0.82     12913\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Word2Vec:\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  15 | elapsed:  4.7min remaining: 13.0min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  15 | elapsed:  4.8min remaining:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  6.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Not Hot       0.74      0.58      0.65      4232\n",
      "         Hot       0.81      0.90      0.85      8681\n",
      "\n",
      "    accuracy                           0.79     12913\n",
      "   macro avg       0.77      0.74      0.75     12913\n",
      "weighted avg       0.79      0.79      0.79     12913\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgboost = XGBoost(random_state=42)\n",
    "xgb_grid = {\"learning_rate\":[0.02, 0.1, 0.5]}\n",
    "xgb_count, xgb_tfidf, xgb_word2vec = benchmark(xgboost, xgb_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency:\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  15 | elapsed:    9.2s remaining:   25.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  15 | elapsed:    9.3s remaining:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   11.0s finished\n",
      "C:\\Users\\guoca\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Not Hot       0.80      0.70      0.75      4232\n",
      "         Hot       0.86      0.92      0.89      8681\n",
      "\n",
      "    accuracy                           0.85     12913\n",
      "   macro avg       0.83      0.81      0.82     12913\n",
      "weighted avg       0.84      0.85      0.84     12913\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "TfIdf:\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of  15 | elapsed:    0.9s remaining:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  15 | elapsed:    1.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Not Hot       0.81      0.71      0.76      4232\n",
      "         Hot       0.87      0.92      0.89      8681\n",
      "\n",
      "    accuracy                           0.85     12913\n",
      "   macro avg       0.84      0.81      0.82     12913\n",
      "weighted avg       0.85      0.85      0.85     12913\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Word2Vec:\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  15 | elapsed:    2.2s remaining:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  15 | elapsed:    2.7s remaining:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Not Hot       0.73      0.65      0.68      4232\n",
      "         Hot       0.84      0.88      0.86      8681\n",
      "\n",
      "    accuracy                           0.80     12913\n",
      "   macro avg       0.78      0.76      0.77     12913\n",
      "weighted avg       0.80      0.80      0.80     12913\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(n_jobs=-1, solver=\"sag\")\n",
    "log_reg_grid = {\"C\":[0.5, 1, 2]}\n",
    "log_reg_count, log_reg_tfidf, log_reg_word2vec = benchmark(log_reg, log_reg_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency:\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    3.7s remaining:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Not Hot       0.75      0.77      0.76      4232\n",
      "         Hot       0.88      0.88      0.88      8681\n",
      "\n",
      "    accuracy                           0.84     12913\n",
      "   macro avg       0.82      0.82      0.82     12913\n",
      "weighted avg       0.84      0.84      0.84     12913\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "TfIdf:\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    1.2s remaining:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Not Hot       0.91      0.45      0.60      4232\n",
      "         Hot       0.78      0.98      0.87      8681\n",
      "\n",
      "    accuracy                           0.80     12913\n",
      "   macro avg       0.85      0.71      0.73     12913\n",
      "weighted avg       0.82      0.80      0.78     12913\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Word2Vec:\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to MultinomialNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[120], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# no searchable parameters, set the grid with default value\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# this simplifies to simple 5-fold CV\u001b[39;00m\n\u001b[0;32m      5\u001b[0m naive_bayes_grid \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;241m1.0\u001b[39m]}\n\u001b[1;32m----> 6\u001b[0m naive_bayes_count, naive_bayes_tdidf, naive_bayes_word2vec \u001b[38;5;241m=\u001b[39m \u001b[43mbenchmark\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnaive_bayes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnaive_bayes_grid\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[112], line 22\u001b[0m, in \u001b[0;36mbenchmark\u001b[1;34m(clf, search_grid)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWord2Vec:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_word2vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m word2vec_clf \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     24\u001b[0m pred_word2vec \u001b[38;5;241m=\u001b[39m word2vec_clf\u001b[38;5;241m.\u001b[39mpredict(test_word2vec)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m as keyword args. From version 0.25 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     68\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassing these as positional arguments will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     69\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult in an error\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(args_msg)),\n\u001b[0;32m     70\u001b[0m                   \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[0;32m     71\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate({k: arg \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args)})\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:765\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    763\u001b[0m refit_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_estimator_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    766\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    767\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:641\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    638\u001b[0m n_effective_classes \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    640\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_counters(n_effective_classes, n_features)\n\u001b[1;32m--> 641\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    642\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_alpha()\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_feature_log_prob(alpha)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:763\u001b[0m, in \u001b[0;36mMultinomialNB._count\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_count\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y):\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;124;03m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 763\u001b[0m     \u001b[43mcheck_non_negative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMultinomialNB (input X)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m safe_sparse_dot(Y\u001b[38;5;241m.\u001b[39mT, X)\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1046\u001b[0m, in \u001b[0;36mcheck_non_negative\u001b[1;34m(X, whom)\u001b[0m\n\u001b[0;32m   1043\u001b[0m     X_min \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mmin()\n\u001b[0;32m   1045\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_min \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1046\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegative values in data passed to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m whom)\n",
      "\u001b[1;31mValueError\u001b[0m: Negative values in data passed to MultinomialNB (input X)"
     ]
    }
   ],
   "source": [
    "naive_bayes = MultinomialNB()\n",
    "\n",
    "# no searchable parameters, set the grid with default value\n",
    "# this simplifies to simple 5-fold CV\n",
    "naive_bayes_grid = {\"alpha\":[1.0]}\n",
    "naive_bayes_count, naive_bayes_tdidf, naive_bayes_word2vec = benchmark(naive_bayes, naive_bayes_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency:\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  9.7min remaining: 14.5min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[126], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m svm \u001b[38;5;241m=\u001b[39m SVC(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      2\u001b[0m svm_grid \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;241m1\u001b[39m]}\n\u001b[1;32m----> 3\u001b[0m svm_count, svm_tfidf, svm_word2vec \u001b[38;5;241m=\u001b[39m \u001b[43mbenchmark\u001b[49m\u001b[43m(\u001b[49m\u001b[43msvm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msvm_grid\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[112], line 5\u001b[0m, in \u001b[0;36mbenchmark\u001b[1;34m(clf, search_grid)\u001b[0m\n\u001b[0;32m      2\u001b[0m clf \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mclf, param_grid\u001b[38;5;241m=\u001b[39msearch_grid, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrequency:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m count_clf \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m      7\u001b[0m pred_count \u001b[38;5;241m=\u001b[39m count_clf\u001b[38;5;241m.\u001b[39mpredict(test_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m as keyword args. From version 0.25 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     68\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassing these as positional arguments will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     69\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult in an error\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(args_msg)),\n\u001b[0;32m     70\u001b[0m                   \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[0;32m     71\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate({k: arg \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args)})\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:736\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    732\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    733\u001b[0m             all_candidate_params, scorers, n_splits, all_out)\n\u001b[0;32m    734\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 736\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;66;03m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;66;03m# best_score_ iff refit is one of the scorer names\u001b[39;00m\n\u001b[0;32m    740\u001b[0m \u001b[38;5;66;03m# In single metric evaluation, refit_metric is \"score\"\u001b[39;00m\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefit \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultimetric_:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# If callable, refit is expected to return the index of the best\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# parameter set.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1188\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1187\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1188\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:708\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    705\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    706\u001b[0m               n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits))\n\u001b[1;32m--> 708\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    712\u001b[0m \u001b[43m                                       \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[43m               \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m               \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    718\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    719\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    720\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1061\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1061\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:938\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    936\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 938\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    939\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    940\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 439\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 302\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    303\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "svm = SVC(random_state=42)\n",
    "svm_grid = {\"C\":[1]}\n",
    "svm_count, svm_tfidf, svm_word2vec = benchmark(svm, svm_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_regression(actual, predicted):\n",
    "    \"\"\"Infer the accuracy, precision, and recall based on regression results.\"\"\"\n",
    "    true_hot = 0\n",
    "    true_not_hot = 0\n",
    "    false_hot = 0\n",
    "    false_not_hot = 0\n",
    "    \n",
    "    for m, n in np.nditer([actual, predicted]):\n",
    "        if m >= 4:\n",
    "            if n >= 4:\n",
    "                true_hot += 1\n",
    "            else:\n",
    "                false_not_hot += 1\n",
    "        else:\n",
    "            if n >= 4:\n",
    "                false_hot += 1\n",
    "            else:\n",
    "                true_not_hot += 1\n",
    "    \n",
    "    total = true_hot + true_not_hot + false_hot + false_not_hot\n",
    "    return (true_hot + true_not_hot) / total, true_hot / (true_hot + false_hot), true_hot / (true_hot + false_not_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg = RFR(n_jobs=-1, random_state=42)\n",
    "rf_reg.fit(train_count, y_train)\n",
    "rf_reg_count_pred = rf_reg.predict(test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count:\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[130], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCount:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43meval_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrf_reg_count_pred\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[127], line 21\u001b[0m, in \u001b[0;36meval_regression\u001b[1;34m(actual, predicted)\u001b[0m\n\u001b[0;32m     18\u001b[0m             true_not_hot \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     20\u001b[0m total \u001b[38;5;241m=\u001b[39m true_hot \u001b[38;5;241m+\u001b[39m true_not_hot \u001b[38;5;241m+\u001b[39m false_hot \u001b[38;5;241m+\u001b[39m false_not_hot\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (true_hot \u001b[38;5;241m+\u001b[39m true_not_hot) \u001b[38;5;241m/\u001b[39m total, \u001b[43mtrue_hot\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_hot\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfalse_hot\u001b[49m\u001b[43m)\u001b[49m, true_hot \u001b[38;5;241m/\u001b[39m (true_hot \u001b[38;5;241m+\u001b[39m false_not_hot)\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "print(\"Count:\")\n",
    "print(eval_regression(y_test, rf_reg_count_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg.fit(train_tfidf, y_train)\n",
    "rf_reg_tfidf_pred = rf_reg.predict(test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TfIdf:\")\n",
    "print(eval_regression(y_test, rf_reg_tfidf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg.fit(train_word2vec, y_train)\n",
    "rf_reg_word2vec_pred = rf_reg.predict(test_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Word2Vec:\")\n",
    "print(eval_regression(y_test, rf_reg_word2vec_pred))\n",
    "print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"Models/Encodings/train_count.npz\", train_count)\n",
    "np.savez_compressed(\"Models/Encodings/train_tfidf.npz\", train_tfidf)\n",
    "np.savez_compressed(\"Models/Encodings/train_word2vec.npz\", train_word2vec)\n",
    "np.savez_compressed(\"Models/Encodings/test_count.npz\", test_count)\n",
    "np.savez_compressed(\"Models/Encodings/test_tfidf.npz\", test_tfidf)\n",
    "np.savez_compressed(\"Models/Encodings/test_word2vec.npz\", test_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Models/log_reg_word2vec.joblib']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(rf_count, \"Models/rf_count.joblib\")\n",
    "dump(rf_tfidf, \"Models/rf_tfidf.joblib\")\n",
    "dump(rf_word2vec, \"Models/rf_word2vec.joblib\")\n",
    "dump(xgb_count, \"Models/xgb_count.joblib\")\n",
    "dump(xgb_tfidf, \"Models/xgb_tfidf.joblib\")\n",
    "dump(xgb_word2vec, \"Models/xgb_word2vec.joblib\")\n",
    "dump(log_reg_count, \"Models/log_reg_count.joblib\")\n",
    "dump(log_reg_tfidf, \"Models/log_reg_tfidf.joblib\")\n",
    "dump(log_reg_word2vec, \"Models/log_reg_word2vec.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
