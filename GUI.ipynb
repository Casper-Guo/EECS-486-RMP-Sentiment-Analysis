{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0559590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tkinter as tk  \n",
    "from tkinter import ttk\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36550b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ad9a38",
   "metadata": {},
   "source": [
    "# Ingest Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be05b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = pd.read_csv(\"Data/clean_ratings.csv\", infer_datetime_format=True)\n",
    "\n",
    "df_profs = pd.read_csv(\"Data/clean_prof_info.csv\")\n",
    "df_profs[\"firstName\"] = df_profs[\"firstName\"].apply(lambda x: x.strip())\n",
    "df_profs[\"lastName\"] = df_profs[\"lastName\"].apply(lambda x: x.strip())\n",
    "\n",
    "df_names = df_profs[[\"profID\", \"firstName\", \"lastName\"]]\n",
    "df_ratings = df_ratings.merge(df_names, how=\"inner\", on=\"profID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874f257b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "stopword_list = set(stopwords.words(\"english\"))\n",
    "stopword_list.update([',', '.'])\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_comment(row):\n",
    "    \"\"\"\n",
    "    Tokenize, remove stopwords and punctuations at word ends, lemmatize, and then reassemble into one string.\n",
    "    \n",
    "    If any token matches the first or last name of the professor, it is dropped.\n",
    "    \n",
    "    All numbers are dropped.\n",
    "    \n",
    "    This is done to eliminate low-impact tokens and reduce vocabulary size.\n",
    "    \n",
    "    String type output required for easier ingestion by sklearn TfidfVectorizer.\n",
    "    \"\"\"\n",
    "    comment = row.loc[\"comment\"]\n",
    "    re.sub(r\"['!\\\"#$%&\\'()*,./:;<=>?@[\\\\]^_`{|}~'] \", ' ', comment)\n",
    "    tokens = word_tokenize(comment)\n",
    "    \n",
    "    ignore_list = stopword_list.copy()\n",
    "    ignore_list.update([row.loc[\"firstName\"], row.loc[\"lastName\"]])\n",
    "    \n",
    "    tokens = [token.lower() for token in tokens if token not in ignore_list and not token.isnumeric()]\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85af0343",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings[\"comment\"] = df_ratings.apply(preprocess_comment, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b77e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings[\"Hot\"] = df_ratings[\"helpfulRating\"] >= 4\n",
    "df_ratings[\"Hot\"] = df_ratings[\"Hot\"].astype(int)\n",
    "\n",
    "X, y = df_ratings[\"comment\"], df_ratings[\"Hot\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a1bad1",
   "metadata": {},
   "source": [
    "# Train Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce74eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(strip_accents=\"ascii\")\n",
    "tfidf_vectorizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a16421",
   "metadata": {},
   "source": [
    "# Load Trained Models\n",
    "\n",
    "Unable to recover XGBoost model, needs retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9488a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = load(\"Models/log_reg_tfidf.joblib\")\n",
    "random_forest = load(\"Models/rf_tfidf.joblib\")\n",
    "svm = load(\"Models/svm_tfidf.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32120fa7",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be89a54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29151753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier as XGBoost\n",
    "\n",
    "# Hyperparameters selected by prior grid search\n",
    "xgboost = XGBoost(learning_rate=0.5, n_estimators=200, random_state=42)\n",
    "xgboost.fit(train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a11f52f",
   "metadata": {},
   "source": [
    "# GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfd5fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class demo_gui:\n",
    "    def __init__(self, root):\n",
    "        \n",
    "        root.title(\"Interactive Demo\")\n",
    "\n",
    "        mainframe = ttk.Frame(root, padding=\"3 3 12 12\")\n",
    "        mainframe.grid(column=0, row=0, sticky=(tk.N, tk.W, tk.E, tk.S))\n",
    "        root.columnconfigure(0, weight=1)\n",
    "        root.rowconfigure(0, weight=1)\n",
    "\n",
    "        self.text = tk.StringVar()\n",
    "        text_entry = ttk.Entry(mainframe, width=100, textvariable=self.text)\n",
    "        text_entry.grid(column=2, row=1, sticky=(tk.W, tk.E))\n",
    "\n",
    "        ttk.Button(mainframe, text=\"Predict\", command=self.predict).grid(column=3, row=1, sticky=(tk.W, tk.E))\n",
    "\n",
    "        ttk.Label(mainframe, text=\"Enter a comment\").grid(column=1, row=1, sticky=(tk.W, tk.E))\n",
    "        ttk.Label(mainframe, text=\"Processed Comment\").grid(column=1, row=2, sticky=(tk.W, tk.E))\n",
    "        ttk.Label(mainframe, text=\"Random Forest\").grid(column=1, row=3, sticky=(tk.W, tk.E))\n",
    "        ttk.Label(mainframe, text=\"XGBoost\").grid(column=1, row=4, sticky=(tk.W, tk.E))\n",
    "        ttk.Label(mainframe, text=\"Logistic Regression\").grid(column=1, row=5, sticky=(tk.W, tk.E))\n",
    "        ttk.Label(mainframe, text=\"Support Vector Machine\").grid(column=1, row=6, sticky=(tk.W, tk.E))\n",
    "        \n",
    "        self.tokens = tk.StringVar()\n",
    "        ttk.Label(mainframe, textvariable=self.tokens).grid(column=2, row=2, sticky=(tk.W, tk.E))\n",
    "        \n",
    "        self.rf_pred = tk.StringVar()\n",
    "        ttk.Label(mainframe, textvariable=self.rf_pred).grid(column=2, row=3, sticky=(tk.W, tk.E))\n",
    "        \n",
    "        self.xgb_pred = tk.StringVar()\n",
    "        ttk.Label(mainframe, textvariable=self.xgb_pred).grid(column=2, row=4, sticky=(tk.W, tk.E))\n",
    "\n",
    "        self.lgr_pred = tk.StringVar()\n",
    "        ttk.Label(mainframe, textvariable=self.lgr_pred).grid(column=2, row=5, sticky=(tk.W, tk.E))\n",
    "\n",
    "        self.svm_pred = tk.StringVar()\n",
    "        ttk.Label(mainframe, textvariable=self.svm_pred).grid(column=2, row=6, sticky=(tk.W, tk.E))\n",
    "        \n",
    "        for child in mainframe.winfo_children(): \n",
    "            child.grid_configure(padx=10, pady=5)\n",
    "\n",
    "        text_entry.focus()\n",
    "    \n",
    "    def predict(self):\n",
    "        tokens, matrix = self.process_input()\n",
    "        \n",
    "        if not tokens:\n",
    "            self.tokens.set('')\n",
    "            self.rf_pred.set('')\n",
    "            self.xgb_pred.set('')\n",
    "            self.lgr_pred.set('')\n",
    "            self.svm_pred.set('')\n",
    "            \n",
    "            return\n",
    "        \n",
    "        self.tokens.set(tokens)\n",
    "        self.rf_pred.set(self.random_forest_predict(random_forest, matrix))\n",
    "        self.xgb_pred.set(self.xgboost_predict_proba(xgboost, matrix))\n",
    "        self.lgr_pred.set(self.logistic_regression_predict(logistic_regression, matrix))\n",
    "        self.svm_pred.set(self.support_vector_machine_predict(svm, matrix))\n",
    "    \n",
    "\n",
    "    def process_input(self):\n",
    "        text = self.text.get()\n",
    "        re.sub(r\"['!\\\"#$%&\\'()*,./:;<=>?@[\\\\]^_`{|}~'] \", ' ', text)\n",
    "        tokens = word_tokenize(text)\n",
    "\n",
    "        tokens = [token.lower() for token in tokens if token not in stopword_list and not token.isnumeric()]\n",
    "        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "        tokens = ' '.join(tokens)\n",
    "\n",
    "        return tokens, tfidf_vectorizer.transform([tokens])\n",
    "    \n",
    "    \n",
    "    def random_forest_predict(self, clf, encoding):\n",
    "        pred = clf.predict_proba(encoding)\n",
    "        \n",
    "        return f\"Hot probability: {round(pred[0, 1], 2)}, not hot probability: {round(pred[0, 0], 2)}\"\n",
    "    \n",
    "    \n",
    "    def logistic_regression_predict(self, clf, encoding):\n",
    "        pred = clf.predict_proba(encoding)\n",
    "        \n",
    "        return f\"Hot probability: {round(pred[0, 1], 2)}, not hot probability: {round(pred[0, 0], 2)}\"\n",
    "    \n",
    "    \n",
    "    def support_vector_machine_predict(self, clf, encoding):\n",
    "        pred = clf.predict(encoding)\n",
    "        hot_or_not = \"Hot\" if pred[0] else \"Not hot\"\n",
    "        \n",
    "        return f\"Predicted class: {hot_or_not}\"\n",
    "    \n",
    "    \n",
    "    def xgboost_predict_proba(self, clf, encoding):\n",
    "        pred = clf.predict_proba(encoding)\n",
    "        \n",
    "        return f\"Hot probability: {round(pred[0, 1], 2)}, not hot probability: {round(pred[0, 0], 2)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8e6924",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = tk.Tk()\n",
    "demo_gui(root)\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
